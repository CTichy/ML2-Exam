Question,Option,IsCorrect,Explanation
What is the role of λ in controlling model complexity?,A smaller λ increases model flexibility,True,A smaller lambda allows coefficients to remain large which leads to a more flexible and potentially overfitting model.
What is the role of λ in controlling model complexity?,A higher λ always improves model accuracy,False,A high lambda reduces complexity but can lead to underfitting if too large, harming accuracy.
What is the role of λ in controlling model complexity?,λ acts as a regularization weight that balances the RSS and penalty term,True,It controls how much we penalize large coefficients thus managing the bias-variance trade-off.
What is the role of λ in controlling model complexity?,λ only affects the intercept term,False,Lambda affects all coefficients except the intercept which is usually excluded from regularization.
How does Lasso behave when predictors are highly correlated?,Lasso tends to randomly pick one feature and ignore others,True,Due to the nature of L1 penalty, Lasso cannot easily distribute weights across correlated predictors.
How does Lasso behave when predictors are highly correlated?,Lasso distributes weight evenly across correlated features,False,That behavior is typical of Ridge regression, not Lasso.
How does Lasso behave when predictors are highly correlated?,Lasso may yield unstable feature selection when variables are correlated,True,The selection can change depending on slight variations in data because of redundancy in predictors.
How does Lasso behave when predictors are highly correlated?,Lasso performs better than Ridge in all correlated settings,False,Ridge is more stable when dealing with multicollinearity due to its L2 structure.
Why might a high λ in Ridge regression lead to poor generalization?,It can lead to underfitting by shrinking coefficients too much,True,Excessive shrinkage can oversimplify the model and lose signal from important predictors.
Why might a high λ in Ridge regression lead to poor generalization?,It increases variance and overfits the data,False,A high lambda decreases variance, not increases it.
Why might a high λ in Ridge regression lead to poor generalization?,The model may no longer capture meaningful patterns,True,When coefficients approach zero, even important features can be suppressed leading to a poor fit.
Why might a high λ in Ridge regression lead to poor generalization?,It allows coefficients to grow arbitrarily,False,A high lambda penalizes large coefficients which is the opposite effect.
What does it mean for Lasso to create a sparse model?,Many coefficients are exactly zero,True,Lasso uses L1 penalty which can zero out less important coefficients entirely.
What does it mean for Lasso to create a sparse model?,The model includes all available predictors,False,Unlike Ridge, Lasso performs feature selection and typically excludes irrelevant predictors.
What does it mean for Lasso to create a sparse model?,The model tends to be more interpretable,True,With fewer predictors included, the model is simpler to understand.
What does it mean for Lasso to create a sparse model?,It always retains the same set of variables in different runs,False,Lasso's feature selection can be unstable, especially with correlated predictors or small samples.
Why is cross-validation necessary when choosing λ?,To avoid overfitting or underfitting by tuning complexity,True,Cross-validation estimates generalization error and helps find the lambda that minimizes it.
Why is cross-validation necessary when choosing λ?,Because higher λ always gives better test accuracy,False,There's no guarantee higher lambda improves test accuracy — it may lead to underfitting.
Why is cross-validation necessary when choosing λ?,To find the λ that minimizes training error,False,Training error always decreases with lower λ; the goal is minimizing validation (test) error.
Why is cross-validation necessary when choosing λ?,Because the optimal λ varies depending on the dataset,True,The right regularization strength depends on data characteristics and noise level.
